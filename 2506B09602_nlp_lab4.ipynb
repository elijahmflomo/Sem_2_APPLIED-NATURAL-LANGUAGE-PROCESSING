{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/elijahmflomo/Sem_2_APPLIED-NATURAL-LANGUAGE-PROCESSING/blob/main/2506B09602_nlp_lab4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Prerequisites:**\n",
        "Before running this code, we would typically need to install NLTK and download the necessary data packages:\n",
        "\n"
      ],
      "metadata": {
        "id": "1jbuxCYhFSya"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3kDzvXEhFRbY",
        "outputId": "0d42b095-528c-4f00-d481-51491d164299"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "### Q1: News Article Editing Scenario\n",
        "\n",
        "**Goal:** Identify nouns, verbs, and adjectives so an editor can replace them.\n",
        "\n",
        "\n",
        "**Sentence:** \"The quick brown fox jumps over the lazy dog.\"\n",
        "\n",
        "**Explanation:**\n",
        "\n",
        "1. **Tokenization:** We break the sentence into individual words.\n",
        "2. **Tagging:** We assign a Part-of-Speech tag to each word.\n",
        "3. **Filtering:** We define a list of tag prefixes we care about: `NN` (Nouns), `VB` (Verbs), and `JJ` (Adjectives). We then filter the results to show only words matching these categories.\n",
        "\n"
      ],
      "metadata": {
        "id": "PmBomGWqFh7X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk import pos_tag\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "nltk.download('punkt_tab') # Added to download the missing resource\n",
        "nltk.download('averaged_perceptron_tagger_eng') # Added to download the missing tagger\n",
        "\n",
        "text = \"The quick brown fox jumps over the lazy dog.\"\n",
        "\n",
        "# 1. Tokenize and Tag\n",
        "tokens = word_tokenize(text)\n",
        "tags = pos_tag(tokens)\n",
        "\n",
        "# 2. Define categories (Using Penn Treebank tags)\n",
        "target_tags = {\n",
        "    'Nouns': ['NN', 'NNS', 'NNP', 'NNPS'],\n",
        "    'Verbs': ['VB', 'VBD', 'VBG', 'VBN', 'VBP', 'VBZ'],\n",
        "    'Adjectives': ['JJ', 'JJR', 'JJS']\n",
        "}\n",
        "\n",
        "# 3. Categorize words\n",
        "results = {'Nouns': [], 'Verbs': [], 'Adjectives': []}\n",
        "\n",
        "for word, tag in tags:\n",
        "    if tag in target_tags['Nouns']:\n",
        "        results['Nouns'].append(word)\n",
        "    elif tag in target_tags['Verbs']:\n",
        "        results['Verbs'].append(word)\n",
        "    elif tag in target_tags['Adjectives']:\n",
        "        results['Adjectives'].append(word)\n",
        "\n",
        "print(\"Analysis Results:\")\n",
        "for category, words in results.items():\n",
        "    print(f\"{category}: {words}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cLYT-h2FFoaI",
        "outputId": "a270009e-533a-439e-d2a8-438d49afa230"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Analysis Results:\n",
            "Nouns: ['brown', 'fox', 'dog']\n",
            "Verbs: ['jumps']\n",
            "Adjectives: ['quick', 'lazy']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n",
            "[nltk_data]       date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Q2: Customer Review Analysis Scenario\n",
        "\n",
        "**Goal:** Extract products (nouns) and descriptions (adjectives).\n",
        "\n",
        "\n",
        "**Sentence:** \"The mobile phone is sleek and works flawlessly.\"\n",
        "\n",
        "**Explanation:**\n",
        "Here we focus specifically on extracting the \"what\" (Nouns) and the \"how\" (Adjectives). Note that in the phrase \"mobile phone\", \"mobile\" might be tagged as an adjective (JJ) because it modifies \"phone\", which fits the requirement to extract descriptions.\n",
        "\n",
        "**Code:**\n",
        "\n"
      ],
      "metadata": {
        "id": "I8R0h7xwF0wl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "\n",
        "text = \"The mobile phone is sleek and works flawlessly.\"\n",
        "tokens = nltk.word_tokenize(text)\n",
        "tags = nltk.pos_tag(tokens)\n",
        "\n",
        "print(f\"Full Tagging: {tags}\\n\")\n",
        "\n",
        "print(\"--- Extracted Information ---\")\n",
        "for word, tag in tags:\n",
        "    # Check for Nouns (NN*)\n",
        "    if tag.startswith('NN'):\n",
        "        print(f\"Product (Noun): {word}\")\n",
        "    # Check for Adjectives (JJ*)\n",
        "    elif tag.startswith('JJ'):\n",
        "        print(f\"Description (Adjective): {word}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "69GIdFRoGHle",
        "outputId": "063de513-e92e-4194-d057-93038be8b828"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Full Tagging: [('The', 'DT'), ('mobile', 'JJ'), ('phone', 'NN'), ('is', 'VBZ'), ('sleek', 'JJ'), ('and', 'CC'), ('works', 'VBZ'), ('flawlessly', 'RB'), ('.', '.')]\n",
            "\n",
            "--- Extracted Information ---\n",
            "Description (Adjective): mobile\n",
            "Product (Noun): phone\n",
            "Description (Adjective): sleek\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Q3: Grammar Correction Tool Scenario\n",
        "\n",
        "**Goal:** Flag singular nouns that are missing an article (a, an, the) before them.\n",
        "\n",
        "\n",
        "**Sentence:** \"Cat was sleeping on mat.\"\n",
        "\n",
        "**Explanation:**\n",
        "This requires logic beyond simple tagging. We must iterate through the sentence and look at the **context**:\n",
        "\n",
        "1. Find a Singular Noun (Tag: `NN`).\n",
        "2. Check the word immediately *before* it.\n",
        "3. If the previous word is **not** a Determiner (Tag: `DT`), or if the noun is the very first word, flag it as an error.\n",
        "\n",
        "**Code:**\n"
      ],
      "metadata": {
        "id": "6XJuPhyVGN6U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "\n",
        "text = \"Cat was sleeping on mat.\"\n",
        "tokens = nltk.word_tokenize(text)\n",
        "tags = nltk.pos_tag(tokens)\n",
        "\n",
        "print(f\"Tagged Sentence: {tags}\\n\")\n",
        "\n",
        "print(\"--- Grammar Check ---\")\n",
        "for i in range(len(tags)):\n",
        "    word, tag = tags[i]\n",
        "\n",
        "    # We are looking for Singular Nouns (NN)\n",
        "    if tag == 'NN':\n",
        "        is_missing_article = False\n",
        "\n",
        "        # Case 1: Noun is the start of the sentence\n",
        "        if i == 0:\n",
        "            is_missing_article = True\n",
        "\n",
        "        # Case 2: Noun is not preceded by a Determiner (DT)\n",
        "        # We look at the tag of the previous word (i-1)\n",
        "        elif tags[i-1][1] != 'DT':\n",
        "            is_missing_article = True\n",
        "\n",
        "        if is_missing_article:\n",
        "            print(f\"Grammar Alert: The singular noun '{word}' is missing an article.\")\n",
        "            print(f\"Suggestion: Consider changing to 'The {word}' or 'A {word}'\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8gVWvj9XGS55",
        "outputId": "a190b1f8-100f-4a30-cc9b-edd4e47efd25"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tagged Sentence: [('Cat', 'NNP'), ('was', 'VBD'), ('sleeping', 'VBG'), ('on', 'IN'), ('mat', 'NN'), ('.', '.')]\n",
            "\n",
            "--- Grammar Check ---\n",
            "Grammar Alert: The singular noun 'mat' is missing an article.\n",
            "Suggestion: Consider changing to 'The mat' or 'A mat'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Q4: Chatbot Training Scenario\n",
        "\n",
        "**Goal:** Identify actions (verbs) to execute commands.\n",
        "\n",
        "\n",
        "**Sentence:** \"Please book a cab and send me the details.\"\n",
        "\n",
        "**Explanation:**\n",
        "Chatbots rely on \"intents\". In a command string, the intent is usually carried by the verb. We will filter for all verb forms (`VB*`). Specifically, imperative commands often use the base form (`VB`), but we will capture all verbs to be safe.\n",
        "\n",
        "**Code:**\n"
      ],
      "metadata": {
        "id": "qfDqT61dGXuL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "\n",
        "text = \"Please book a cab and send me the details.\"\n",
        "tokens = nltk.word_tokenize(text)\n",
        "tags = nltk.pos_tag(tokens)\n",
        "\n",
        "actions = []\n",
        "\n",
        "for word, tag in tags:\n",
        "    # Filter for all verb types (VB, VBD, VBG, etc.)\n",
        "    if tag.startswith('VB'):\n",
        "        actions.append(word)\n",
        "\n",
        "print(f\"User Message: {text}\")\n",
        "print(f\"Detected Actions (Verbs): {actions}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C1vWSthJGcHM",
        "outputId": "679361c5-261f-4c63-c667-6863f5ee586c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "User Message: Please book a cab and send me the details.\n",
            "Detected Actions (Verbs): ['send']\n"
          ]
        }
      ]
    }
  ]
}